% Generated by GrindEQ Word-to-LaTeX 2010 
% LaTeX/AMS-LaTeX

\documentclass{article}

%%% remove comment delimiter ('%') and specify encoding parameter if required,
%%% see TeX documentation for additional info (cp1252-Western,cp1251-Cyrillic)
%\usepackage[cp1252]{inputenc}

%%% remove comment delimiter ('%') and select language if required
%\usepackage[english,spanish]{babel}

\usepackage{amssymb}
\usepackage{amsmath}
\usepackage[dvips]{graphicx}
%%% remove comment delimiter ('%') and specify parameters if required
%\usepackage[dvips]{graphics}

\begin{document}

%%% remove comment delimiter ('%') and select language if required
%\selectlanguage{spanish} 

\noindent 

\noindent 16 Solution Weighting (11.03.2011).docx  2 of 3

\noindent 

\noindent \textbf{16. Weighting the Personnel Survey: One Solution}

The project assigned in Chapter 12 was to compute a set of weights for a survey of members of the military reserves.  A stratified simple random sample of personnel was selected and queried about satisfaction with their jobs.  The project provides an opportunity to put into practice the techniques covered in Chapters 13-15.  Completing the project requires calculation of base weights, an adjustment to account for cases whose eligibility status is unknown, an adjustment for nonresponse, and calibration to some finite population totals. There are several practical problems to be solved, including selecting a particular method of nonresponse adjustment, deciding how to use the population counts that are available, and determining how to handle missing values in both the sample cases and the population counts.

Although this chapter is not written as a formal report to be delivered to a client as was requested in the Chapter 12 assignment, we want to again emphasize the importance of good documentation.  Clear documentation of all weighting steps is critical for several reasons.  It may be necessary to repeat some or all steps at a later time.  For example, errors may be discovered in some details of calculations, or problems may be found in one of the input data sets.  If a survey will be repeated at a later date, a well written weighting report can guide the work in the next survey.  Very detailed specification memos, like the ones described in Chapter 18, will remove any doubt about what should be done and can lead to reduced costs if the survey is repeated at a later date.

The R code for the solution to this project is in the files,

16.1 Solution bwt-unknown adj.R

16.2 Solution NR adj.R

16.3 Solution calibration adj.R

16.4 Example tabulations.R 



\noindent all of which are on the book's website.

\noindent \textbf{16.1 The Data Files}

Two data files were provided for the project.  One file (SOFR.sas7bdat/SOFR.xpt) contained records for all 71,701 sample members who were initially selected. The file includes the 19 variables shown in Table 16.1.  The fields include identification number, final respondent status code, stratum identifier, stratum sample count and population count, frame variables (gender, pay grade, race, etc.), and respondents' answers to key questions. The variable RESPSTAT for final respondent status code has information about the eligibility and the response status for each sample member. 

The fields NSAMP and NSTRAT contain the number of cases in the sample and in the frame for the stratum to which a person belongs.  The values are the same for all records for persons in a given stratum.  Based on inspecting the file of sample persons, there were 404 strata, defined by combinations of branch of the service, race-ethnicity, gender, and paygrade.

\noindent \textbf{Table 16.1.} Contents of data file SOFR.sas7bdat

\begin{tabular}{|p{0.3in}|p{0.8in}|p{2.9in}|} \hline 
\textbf{\#} & \textbf{Variable} & \textbf{Label} \\ \hline 
1 & REC\_ID & Unique Record Identification Number \\ \hline 
2 & RESPSTAT & Final Respondent Status Code \\ \hline 
3 & SRMARST & What is your marital status? \\ \hline 
4 & RA006A & Taking all things into consideration, how satisfied are you, in general, with each of the following aspects of being in the National Guard/Reserve? Your total compensation (i.e., base pay, allowances, and bonuses) \\ \hline 
5 & RA006B & Taking all things into consideration, how satisfied are you, in general, with each of the following aspects of being in the National Guard/Reserve? The type of work you do in your military job \\ \hline 
6 & RA008 & Suppose that you have to decide whether to continue to participate in the National Guard/Reserve. Assuming you could stay, how likely is it that you would choose to do so? \\ \hline 
7 & RA115 & Overall, how well prepared are you to perform your wartime job? \\ \hline 
8 & RA118 & Overall, how would you rate the current level of stress in your personal life? \\ \hline 
9 & SRED & What is the highest degree or level of school that you have completed? Mark the one answer that describes the highest grade or degree that you have completed. \\ \hline 
10 & RA112RA & Average: In past 12 months, how many days did you spend in a compensated Reserve/Guard status? \\ \hline 
11 & XSRRCR & \textbf{Recoded: Imputed Service } \\ \hline 
12 & XACT2R & \textbf{Recoded: Imputed Activated 30 Days - 3 Level }In the last 24 months were you ever activated longer than 30 consecutive days? \\ \hline 
13 & XRETH4R & \textbf{Recoded: Imputed Race/Ethnicity - 2 Level} \\ \hline 
14 & XSEXR & \textbf{Recoded: Imputed Gender} \\ \hline 
15 & XCPAY1R & \textbf{Recoded: Imputed Paygrade Group 1} \\ \hline 
16 & NSAMP & Stratum Sample Count \\ \hline 
17 & NSTRAT & Stratum Population Count \\ \hline 
18 & V\_STRAT & Variance estimation stratum \\ \hline 
19 & STRATUM & Design stratum \\ \hline 
\end{tabular}



\noindent As shown in Table 16.2, the other data file (RCCPDS57.sas7bdat/RCCPDS57.xpt) has population counts for seven frame variables (branch of the service, gender, pay grade, race-ethnicity, education, marital status, and whether a person had been called to active service more than 30 consecutive days in the last 24 months.). These frame variables have different names than in the sample data file, but the alternative names are indicated in the labels.  Population counts are provided in variable COUNT.

\noindent \textbf{Table 16.2.} Contents of data file RCCPDS57.sas7bdat

\begin{tabular}{|p{0.3in}|p{0.8in}|p{2.9in}|} \hline 
\textbf{\#} & \textbf{Variable} & \textbf{Label} \\ \hline 
1 & SERVICE & (XSRRCR) Branch of Military Service \\ \hline 
2 & GENDER & (XSEXR) Gender \\ \hline 
3 & PG\_GROUP & (XCPAY1R) Pay grade group \\ \hline 
4 & RACETH & (XRETH4R) Race/Ethnicity \\ \hline 
5 & EDUCCAT & (SRED) Highest degree/level of school completed \\ \hline 
6 & MARIT & (SRMARST) Current marital status \\ \hline 
7 & ACTIVATD & (XACT2R) Activated more than 30 consecutive days or less in last 24 months \\ \hline 
8 & COUNT & Person count \\ \hline 
\end{tabular}



\noindent \textbf{}

\noindent \textbf{16.2 Base Weights}

Base weights can be computed as soon as the sample is selected.  We do not need to know the dispositions of any of the sample cases because the base weights in this survey depend only on the frame counts and the sample sizes in each of the design strata.  Since a stratified simple random sample was selected, the selection probability of each person \textit{i }in stratum \textit{h }was $\pi _{hi} ={n_{h} \mathord{\left/ {\vphantom {n_{h}  N_{h} }} \right. \kern-\nulldelimiterspace} N_{h} } $ where 

$n_{h} $ = number of persons sampled from stratum \textit{h};

$N_{h} $ = number of persons on the frame in stratum \textit{h}.

\noindent The base weight for person \textit{hi }is the inverse of the selection probability: $w_{hi} ={N_{h} \mathord{\left/ {\vphantom {N_{h}  n_{h} }} \right. \kern-\nulldelimiterspace} n_{h} } $.  This is computed as NSTRAT/NSAMP.  The sum of the base weights is 870,373, which is exactly equal to the count of the persons on the frame since the sample is \textit{stsrs}.

\noindent 

\noindent \textbf{16.3 Disposition Codes and Mapping into Weighting Categories}

Table 16.3 gives counts of persons by the disposition codes in the RESPSTAT field.  These codes are specific to the survey of Reserve personnel, as is apparent from some of the categories.  For example, code 22 (No return---separated/retired) would probably not be used in surveys of most other populations.  Because there was a time lapse between the time the sample was selected and the data were collected, the status of some persons changed.  This is the reason for having codes for retirees, deceased, incarcerated, etc.  Addresses for some personnel are out-of-date leading to the inability of the postal service to deliver the survey (code 27).  To compute weights, the disposition codes need to be mapped into the groups:

\begin{tabular}{|p{0.7in}|p{1.3in}|} \hline 
ER & Eligible respondents \\ \hline 
ENR & Eligible nonrespondents \\ \hline 
IN & Known ineligibles \\ \hline 
UNK & Unknown eligibility \\ \hline 
\end{tabular}



\noindent To compute the various AAPOR response rates described in Chapter 18, the disposition codes are mapped to a slightly different set of categories:

\begin{tabular}{|p{0.7in}|p{1.4in}|} \hline 
I & Complete interview \\ \hline 
P & Partially complete interview \\ \hline 
R & Refusal/Break-off \\ \hline 
NE & Not eligible \\ \hline 
U & Unknown eligibility \\ \hline 
O & Other eligible noninterview \\ \hline 
\end{tabular}



\noindent The mappings we used for both the weighting and AAPOR categories are shown in Table 16.4.  A number of decisions have to be made about how to map the dispositions.  Some choices are obvious, like mapping code 1 (Questionnaire Returned -- Completed) to ER and I.  Others are less so, like codes 5 (Questionnaire Returned -- Blank), 25 (No Return -- Other), 27 Postal non-delivery), and 29 (Not Locatable).  Unless more is known about such cases, a conservative approach would be to consider the eligibility of these persons as unknown, which we did in Table 16.4.  Since there is disposition code 26 (No Return --- eligible based on administrative records), it is apparent that efforts were made to match the sample file against personnel records.  Consequently, the alternative argument could be made that persons in codes 5, 25, 27, and 29 are ineligible.  Clearly, there is some subjectivity in the mapping.

\noindent 

\noindent \textbf{Table 16.3.} Counts for each final respondent status code 

\begin{tabular}{|p{2.7in}|p{0.5in}|} \hline 
Respondent status (as stored in RESPSTAT variable) & Count \\ \hline 
1 = Questionnaire Returned -- Completed & 25,539 \\ \hline 
2 = Questionnaire Returned -- (Sufficient) Partial Complete & 20 \\ \hline 
3 = Questionnaire Returned -- (Insufficient) Partial Complete & 524 \\ \hline 
4 = Questionnaire Returned -- Ineligible & 503 \\ \hline 
5 = Questionnaire Returned -- Blank & 97 \\ \hline 
18 = No Return -- Deceased & 9 \\ \hline 
19 = No Return -- Incarcerated & 2 \\ \hline 
22 = No Return -- Separated/Retired & 35 \\ \hline 
23 = No Return -- Active Refusal & 193 \\ \hline 
25 = No Return -- Other & 8 \\ \hline 
26 = No Return --- eligible based on administrative records & 39,872 \\ \hline 
27 = Postal Non-delivery & 1,339 \\ \hline 
29 = Not Locatable & 6 \\ \hline 
35 = Ineligible -- No Questionnaire Sent & 3,554 \\ \hline 
Total & 71,701 \\ \hline 
\end{tabular}



\noindent \textbf{Table 16.4}. Mapping of disposition codes into collapsed respondent statuses

\begin{tabular}{|p{1.4in}|p{0.6in}|p{1.0in}|p{0.5in}|p{0.8in}|} \hline 
\textbf{Response status (as stored in RESPSTAT)} & \textbf{Weighting code} & \textbf{Weighting category} & \textbf{AAPOR code} & \textbf{AAPOR description} \\ \hline 
1 = Questionnaire Returned -- Completed & ER & Eligible respondent & I & Complete interview \\ \hline 
2 = Questionnaire Returned -- (Sufficient) Partial Complete & ER & Eligible respondent & P & Partially complete interview \\ \hline 
3 = Questionnaire Returned -- (Insufficient) Partial Complete & ENR & Eligible nonrespondent & R & Refusal/Break-off \\ \hline 
4 = Questionnaire Returned -- Ineligible & IN & Ineligible & NE & Not eligible \\ \hline 
5 = Questionnaire Returned -- Blank & UNK & Unknown eligibility  & U & Unknown eligibility \\ \hline 
18 = No Return -- Deceased & IN & Ineligible & NE & Not eligible \\ \hline 
19 = No Return -- Incarcerated & IN & Ineligible & NE & Not eligible \\ \hline 
22 = No Return -- Separated/Retired & IN & Ineligible & NE & Not eligible \\ \hline 
23 = No Return -- Active Refusal & ENR & Eligible nonrespondent & R & Refusal/Break-off \\ \hline 
25 = No Return -- Other & UNK & Unknown eligibility & U & Unknown eligibility \\ \hline 
26 = No Return --- eligible based on administrative records & ENR & Eligible nonrespondent & O & Other eligible noninterview \\ \hline 
27 = Postal Non-delivery & UNK & Unknown eligibility  & U & Unknown eligibility \\ \hline 
29 = Not Locatable & UNK & Unknown eligibility  & U & Unknown eligibility \\ \hline 
35 = Ineligible -- No Questionnaire Sent & IN & Ineligible & NE & Not eligible \\ \hline 
\end{tabular}



Table 16.5 shows the counts of cases in the weighting and AAPOR categories.  Judging from the counts, unknown eligibility is a minor problem.  On the other hand, the response rate is well under 50\%.  Thus, concentrating efforts on the nonresponse adjustment is prudent in this sample.

\noindent \textbf{\eject }

\noindent \textbf{Table 16.5}. Counts for each weighting and AAPOR category

\begin{tabular}{|p{1.8in}|p{0.4in}|p{0.5in}|p{0.5in}|} \hline 
Disposition & Indicator & Count & Percent \\ \hline 
\multicolumn{2}{|p{1in}|}{Weighting category (disposition codes)} &  &  \\ \hline 
Eligible respondent (1,2) & ER & 25,559  & 35.6 \\ \hline 
Eligible nonrespondent (3,23,26) & NR & 40,589  & 56.6 \\ \hline 
Known ineligible (4,18,19,22,35) & IN & 4,103  & 5.7 \\ \hline 
Unknown eligibility (5,25,27,29) & UNK & 1,450  & 2.0 \\ \hline 
Total &  & 71,701  & 100.0 \\ \hline 
 &  &  &  \\ \hline 
AAPOR category (disposition codes) &  &  &  \\ \hline 
Complete \eqref{GrindEQ__1_} & I & 25,539  & 35.6 \\ \hline 
Partial \eqref{GrindEQ__2_} & P & 20  & 0.03 \\ \hline 
Refusal/Break-off (3,23) & R & 717  & 1.0 \\ \hline 
Other eligible noninterview \eqref{GrindEQ__26_} & O & 39,872  & 55.6 \\ \hline 
Not eligible (4, 18, 19, 22, 35) & NE & 4,103  & 5.7 \\ \hline 
Unknown eligibility (5, 25, 27, 29) & U & 1,450  & 2.0 \\ \hline 
Total &  & 71,701 & 100.0 \\ \hline 
\end{tabular}



Chapter 18 reviewed various outcome rates that may be computed in a survey.  As illustrations, we compute \textit{RR}1\textit{ }and \textit{RR}4 which are defined as:

\noindent $RR1{\rm =}\frac{100I}{(I+P)+(R+O)+U} $ and

\noindent $RR4=\frac{100\left(I+P\right)}{I+P+R+O+e*U} $ where
\[e=\frac{I+P+R+O}{I+P+R+O+NE} \] 
is the proportion of unknowns that are allocated to being eligible.  In this sample, \textit{e} = 0.941, \textit{RR}1\textit{ }= 37.78\%, and \textit{RR}4\textit{ }= 37.83\%.  Since the number of unknowns is a small part of the full sample, the values of these two response rates are virtually the same.

\noindent 

\noindent \textbf{16.4 Adjustment for Unknown Eligibility}

Using the base weights, we can estimate the numbers of persons on the frame that are in the weighting categories, ER, ENR, IN, and UNK:

\noindent 

\begin{tabular}{|p{1.5in}|p{0.5in}|p{0.8in}|p{0.6in}|} \hline 
Weighting category &  & Estimated count & Percentage \\ \hline 
Eligible respondent & ER & 320,677  & 36.8\% \\ \hline 
Eligible nonrespondent & NR & 474,675  & 54.5\% \\ \hline 
Known ineligible & IN & 55,770  & 6.4\% \\ \hline 
Unknown eligibility & UNK & 19,251  & 2.2\% \\ \hline 
Total &  & 870,373  & 100.0\% \\ \hline 
\end{tabular}



\noindent The estimated population counts are distributed in about the same way as the unweighted counts in Table 16.5.  Since only 2.2\% of the frame is estimated to be unknowns, we will make one overall adjustment, which, using the notation from section 14.2, is equal to 
\[a_{1} =\frac{\sum _{i\, \in s}d_{0i}  }{\sum _{i\in s_{KN} }d_{0i}  } =\frac{{\rm 32}0,{\rm 677}\; +{\rm 474},{\rm 675+}\; {\rm 55},{\rm 77}0}{870,373} ={\rm 1}.0{\rm 226}.\] 
The adjustment is made in the file 16.1 Solution bwt-unknown adj.R.

\noindent 

\noindent \textbf{16.5 Adjustment for Nonresponse}

There are four variables that have non-missing data for both the sample respondents and nonrespondents: branch of the service, race-ethnicity, gender, and paygrade.  These are the same variables that were used in defining design strata. The other personal characteristics---education, marital status, and whether a person spent more than 30 consecutive days on active duty in the last 24 months---are each missing for almost all nonrespondents.  Table 16.6a shows sample counts of responding and nonresponding persons for each of the variables that we can use for nonresponse adjustment; Table 16.6b shows similar counts for the other three demographic variables that are available mainly for respondents.  The two tables also show population counts from the RCCPDS57.XPT file.  

The file from which population counts were made had some missing data for each variable, other than pay group.  For example, branch of the service in Table 16.6a was missing for 291 persons; race-ethnicity was missing for 602 persons.  Later, in section 16.\_, when we calibrate to the population counts, imputations will have to be made for those missing values.

\noindent 

\noindent \textbf{}

\noindent \textbf{Table 16.6a}. Sample counts of respondents and nonrespondents and population counts for the four variables with no missing data for sample persons.

\begin{tabular}{|p{1.2in}|p{0.5in}|p{0.5in}|p{0.5in}|p{0.5in}|p{0.5in}|p{0.6in}|p{0.5in}|} \hline 
(Code value) Variable & \multicolumn{2}{|p{1.0in}|}{Nonrespondent} & \multicolumn{2}{|p{1.0in}|}{Respondent} & ~ & \multicolumn{2}{|p{1.1in}|}{Population controls (before imputation)} \\ \hline 
~ & \textit{n} & \% & \textit{n} & \% & Total~ & \textit{N} & \% \\ \hline 
\textbf{Service} & ~ &  & ~ &  &  & ~ &  \\ \hline 
 \eqref{GrindEQ__1_} Army National Guard & 10,060 & 65.0\% & 5,424 & 35.0\% & 15,484 &     322,053  & 40.2\% \\ \hline 
 \eqref{GrindEQ__2_} Army Reserve & 8,398 & 61.9\% & 5,179 & 38.1\% & 13,577 &     190,235  & 23.7\% \\ \hline 
 \eqref{GrindEQ__3_} Naval Reserve & 4,686 & 56.4\% & 3,617 & 43.6\% & 8,303 &       77,022  & 9.6\% \\ \hline 
 \eqref{GrindEQ__4_} Marine Corps Reserve & 7,869 & 70.6\% & 3,283 & 29.4\% & 11,152 &       36,094  & 4.5\% \\ \hline 
 \eqref{GrindEQ__5_} Air National Guard & 4,855 & 53.6\% & 4,207 & 46.4\% & 9,062 &     105,092  & 13.1\% \\ \hline 
 \eqref{GrindEQ__6_} Air Force Reserve & 4,721 & 55.1\% & 3,849 & 44.9\% & 8,570 &       71,022  & 8.9\% \\ \hline 
 Missing & --- & --- & --- & --- & --- &           291  & 0.04\% \\ \hline 
\textbf{Race-ethnicity} & ~ &  & ~ &  &  & ~ &  \\ \hline 
 \eqref{GrindEQ__1_} NonHispanic White & 20,625 & 55.1\% & 16,833 & 44.9\% & 37,458 &     540,473  & 67.4\% \\ \hline 
 \eqref{GrindEQ__2_} Total Minority & 19,964 & 69.6\% & 8,726 & 30.4\% & 28,690 &     260,734  & 32.5\% \\ \hline 
 Missing & --- & --- & --- & --- & --- &           602  & 0.1\% \\ \hline 
\textbf{Gender} & ~ &  & ~ &  &  & ~ &  \\ \hline 
 \eqref{GrindEQ__1_} Male & 34,100 & 61.9\% & 21,007 & 38.1\% & 55,107 &     663,122  & 82.7\% \\ \hline 
 \eqref{GrindEQ__2_} Female & 6,489 & 58.8\% & 4,552 & 41.2\% & 11,041 &     138,574  & 17.3\% \\ \hline 
 Missing & --- & --- & --- & --- & --- &           113  & 0.01\% \\ \hline 
\textbf{Pay Group} & ~ &  & ~ &  &  & ~ &  \\ \hline 
 \eqref{GrindEQ__1_} E1 - E3   & 7,026 & 82.5\% & 1,494 & 17.5\% & 8,520 &     112,244  & 14.0\% \\ \hline 
 \eqref{GrindEQ__2_} E4 & 12,936 & 75.8\% & 4,125 & 24.2\% & 17,061 &     198,048  & 24.7\% \\ \hline 
 \eqref{GrindEQ__3_} E5 - E6 & 10,146 & 64.2\% & 5,653 & 35.8\% & 15,799 &     265,388  & 33.1\% \\ \hline 
 \eqref{GrindEQ__4_} E7 - E9 & 2,810 & 47.1\% & 3,162 & 52.9\% & 5,972 &     110,397  & 13.8\% \\ \hline 
 \eqref{GrindEQ__5_} W1 - W5 & 987 & 42.1\% & 1,356 & 57.9\% & 2,343 &       10,948  & 1.4\% \\ \hline 
 \eqref{GrindEQ__6_} O1 - O3 & 3,185 & 45.7\% & 3,783 & 54.3\% & 6,968 &       41,176  & 5.1\% \\ \hline 
 \eqref{GrindEQ__7_} O4 - O6 & 3,499 & 36.9\% & 5,986 & 63.1\% & 9,485 &       63,608  & 7.9\% \\ \hline 
 Missing & --- & --- & --- & --- & --- &  ---  &  ---  \\ \hline 
 & ~ &  & ~ &  &  & ~ &  \\ \hline 
Grand totals & 40,589 & 61.4\% & 25,559 & 38.6\% & 66,148 &     801,809  & 100.0\% \\ \hline 
\end{tabular}

\textbf{}

\noindent \textbf{Table 16.6b}. Sample counts of respondents and nonrespondents and population counts for education level, marital status, and activation. 

\begin{tabular}{|p{1.2in}|p{0.5in}|p{0.5in}|p{0.5in}|p{0.5in}|p{0.5in}|p{0.6in}|p{0.5in}|} \hline 
(Code value) Variable & \multicolumn{2}{|p{1.0in}|}{Nonrespondent} & \multicolumn{2}{|p{1.1in}|}{Respondent} & ~ & \multicolumn{2}{|p{1.1in}|}{Population controls (before imputation)} \\ \hline 
~ & \textit{n} & \% & \textit{n} & \% & Total~ & \textit{N} & \% \\ \hline 
\textbf{Education} & ~ &  & ~ &  &  & ~ &  \\ \hline 
 \eqref{GrindEQ__1_} 12 years or less of school (no diploma) & 0 & 0.0\% & 146 & 100.0\% & 146 &       10,819  & 1.3\% \\ \hline 
 \eqref{GrindEQ__2_} High school graduate--high school diploma or equivalent (e.g., GED) & 0 & 0.0\% & 2,059 & 100.0\% & 2,059 &     116,933  & 14.6\% \\ \hline 
 \eqref{GrindEQ__3_} Some college credit, but less than 1 year & 1 & 0.0\% & 2,465 & 100.0\% & 2,466 &     113,512  & 14.2\% \\ \hline 
 \eqref{GrindEQ__4_} 1 or more years of college, no degree & 2 & 0.0\% & 4,967 & 100.0\% & 4,969 &     223,581  & 27.9\% \\ \hline 
 \eqref{GrindEQ__5_} Associate's degree & 1 & 0.0\% & 2,399 & 100.0\% & 2,400 &       96,073  & 12.0\% \\ \hline 
 \eqref{GrindEQ__6_} Bachelor's degree & 8 & 0.1\% & 7,750 & 99.9\% & 7,758 &     147,450  & 18.4\% \\ \hline 
 \eqref{GrindEQ__7_} Master's, doctoral or professional school degree & 1 & 0.0\% & 4,912 & 100.0\% & 4,913 &       66,614  & 8.3\% \\ \hline 
 Missing  & 40,576 & 97.9\% & 861 & 2.1\% & 41,437 &       26,827  & 3.3\% \\ \hline 
\textbf{Marital status} & ~ &  & ~ &  &  & ~ &  \\ \hline 
 \eqref{GrindEQ__1_} Married & 233 & 1.4\% & 16,934 & 98.6\% & 17,167 &     455,603  & 56.8\% \\ \hline 
 \eqref{GrindEQ__2_} Separated & 6 & 1.5\% & 397 & 98.5\% & 403 &       11,748  & 1.5\% \\ \hline 
 \eqref{GrindEQ__3_} Divorced & 40 & 1.6\% & 2,538 & 98.4\% & 2,578 &       75,025  & 9.4\% \\ \hline 
 \eqref{GrindEQ__4_} Widowed & 0 & 0.0\% & 75 & 100.0\% & 75 &         3,324  & 0.4\% \\ \hline 
 \eqref{GrindEQ__5_} Never Married & 157 & 2.7\% & 5,577 & 97.3\% & 5,734 &     254,468  & 31.7\% \\ \hline 
 Missing  & 40153 & 99.9\% & 38 & 0.1\% & 40,191 &         1,641  & 0.2\% \\ \hline 
\textbf{Activated more than 30 days} & ~ &  & ~ &  &  & ~ &  \\ \hline 
 \eqref{GrindEQ__1_} Activated $<$= 30 Days & 7 & 1.1\% & 611 & 98.9\% & 618 &       37,171  & 4.6\% \\ \hline 
 \eqref{GrindEQ__2_} Activated $>$ 30 Days & 148 & 1.1\% & 12,912 & 98.9\% & 13,060 &     250,808  & 31.3\% \\ \hline 
 \eqref{GrindEQ__3_} Not activated & 24 & 0.2\% & 11,814 & 99.8\% & 11,838 &     508,083  & 63.4\% \\ \hline 
 Missing  & 40,410 & 99.5\% & 222 & 0.5\% & 40,632 &         5,747  & 0.7\% \\ \hline 
 & ~ &  & ~ &  &  & ~ &  \\ \hline 
Grand totals & 40,589 & 61.4\% & 25,559 & 38.6\% & 66,148 &     801,809  & 100.0\% \\ \hline 
\end{tabular}

\textbf{\eject }

\noindent \textbf{16.5 Nonresponse Adjustments}

Two options for nonresponse adjustment that we covered in Chapter 13 are to use estimated response propensities and cells formed with a regression tree.  Both alternatives are examined in this section.

\noindent 

\noindent \textbf{Propensity models}

First, we will examine the option of creating classes based on estimated response probabilities or propensities.  A model with main effects and all two-way interactions, using the four available variables was fitted without using survey weights.  The R code is shown below and is in the file 16.2 Solution NR adj.R.  The variable resp is 1 for respondents and 0 for nonrespondents.

\noindent glm.logit2  $<$-  glm(resp \~{} as.factor(xsrrcr)*as.factor(xreth4r)

\noindent                         + as.factor(xsrrcr)*as.factor(xsexr)

\noindent                         + as.factor(xsrrcr)*as.factor(xcpay1r)

\noindent                         + as.factor(xreth4r)*as.factor(xsexr)

\noindent                         + as.factor(xreth4r)*as.factor(xcpay1r)

\noindent                         + as.factor(xsexr)*as.factor(xcpay1r),

\noindent                         family=binomial(link = "logit"),

\noindent                         data = sofr.d1.elig)

\noindent anova(glm.logit2, test="Chisq")

\noindent 

\noindent The data set sofr.d1.elig is a subset of sofr.sas7bdat that contains only the 66,148 eligible respondents and nonrespondents.  The output from the anova command is shown below. 

\noindent                                       Df Deviance Resid. Df Resid. Dev P($>$\textbar Chi\textbar )    

\noindent  

\noindent as.factor(xsrrcr)                      5    951.3     66142      87304 $<$ 2.2e-16 ***

\noindent as.factor(xreth4r)                     1   1376.9     66141      85927 $<$ 2.2e-16 ***

\noindent as.factor(xsexr)                       1     13.2     66140      85914 0.0002764 ***

\noindent as.factor(xcpay1r)                     6   6081.2     66134      79833 $<$ 2.2e-16 ***

\noindent as.factor(xsrrcr):as.factor(xreth4r)   5     71.0     66129      79762 6.379e-14 ***

\noindent as.factor(xsrrcr):as.factor(xsexr)     5     15.9     66124      79746 0.0070584 ** 

\noindent as.factor(xsrrcr):as.factor(xcpay1r)  30    209.9     66094      79536 $<$ 2.2e-16 ***

\noindent as.factor(xreth4r):as.factor(xsexr)    1     31.2     66093      79505 2.291e-08 ***

\noindent as.factor(xreth4r):as.factor(xcpay1r)  6      7.2     66087      79498 0.3004589    

\noindent as.factor(xsexr):as.factor(xcpay1r)    6     36.8     66081      79461 1.937e-06 ***

\noindent ---

\noindent Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1 



All main effects and interactions are highly significant except for the xreth4r*xcpay1r interaction.  In a survey-weighted regression the same factors and interactions were significant.  With such a large sample size, we could probably find some significant three-way interactions also.  But, for this project we will not attempt to extend the model above.  

Given predicted response probabilities from this model, we can create classes based on their quantiles.  Table 16.7 shows the ranges of propensities and counts of persons in each class when 5 and 10 classes are created.  Notice that the counts of persons in each class are not equal.  Since the model uses only factors as predictors, there are many ties among the estimated propensities, leading to uneven divisions among the classes.  Using 10 classes does seem to distinguish better among different rates than does 5 classes.  The estimated rates within classes in the last five columns of Table 16.7 are fairly similar regardless of the method of calculation.  

\noindent 

\noindent \textbf{\eject }

\noindent \textbf{Table 16.7}  Ranges of estimated response propensities for 5 and 10 classes along with five estimates of response propensity within each class.

\noindent 

\begin{tabular}{|p{1.0in}|p{0.8in}|p{0.7in}|p{0.5in}|p{0.7in}|p{0.6in}|p{0.6in}|} \hline 
Range of estimated propensities & Number of sample persons & Unweighted mean & Weighted mean & Unweighted response rate & Weighted response rate & Median response propensity \\ \hline 
5 classes &  &  &  &  &  &  \\ \hline 
[0.098,0.213] & 13,568  & 0.160 & 0.172 & 0.160 & 0.201 & 0.166 \\ \hline 
(0.213,0.300] & 13,539  & 0.262 & 0.251 & 0.260 & 0.267 & 0.264 \\ \hline 
(0.300,0.446] & 13,077  & 0.375 & 0.387 & 0.380 & 0.416 & 0.375 \\ \hline 
(0.446,0.569] & 13,213  & 0.520 & 0.509 & 0.521 & 0.517 & 0.520 \\ \hline 
(0.569,0.735] & 12,751  & 0.631 & 0.635 & 0.629 & 0.651 & 0.628 \\ \hline 
 &  &  &  &  &  &  \\ \hline 
10 classes &  &  &  &  &  &  \\ \hline 
[0.098,0.166] & 8,218  & 0.140 & 0.147 & 0.141 & 0.177 & 0.137 \\ \hline 
(0.166,0.213] & 5,350  & 0.191 & 0.198 & 0.190 & 0.226 & 0.190 \\ \hline 
(0.213,0.264] & 7,600  & 0.244 & 0.242 & 0.236 & 0.256 & 0.238 \\ \hline 
(0.264,0.300] & 5,939  & 0.285 & 0.284 & 0.290 & 0.313 & 0.281 \\ \hline 
(0.300,0.360] & 6,053  & 0.336 & 0.335 & 0.346 & 0.350 & 0.326 \\ \hline 
(0.360,0.446] & 7,024  & 0.409 & 0.403 & 0.409 & 0.437 & 0.398 \\ \hline 
(0.446,0.519] & 6,182  & 0.481 & 0.472 & 0.478 & 0.494 & 0.484 \\ \hline 
(0.519,0.569] & 7,031  & 0.555 & 0.551 & 0.558 & 0.542 & 0.555 \\ \hline 
(0.569,0.627] & 6,136  & 0.595 & 0.599 & 0.588 & 0.611 & 0.591 \\ \hline 
(0.627,0.735] & 6,615  & 0.665 & 0.667 & 0.667 & 0.687 & 0.649 \\ \hline 
 &  &  &  &  &  &  \\ \hline 
Total & 66,148  & ~ & ~ & ~ & ~ & ~ \\ \hline 
\end{tabular}



\noindent \includegraphics*[width=7.91in, height=5.28in, keepaspectratio=false, trim=0.00in 0.12in 0.00in 0.05in]{image1.eps}

\noindent \textbf{Figure 16.1}  Boxplots of estimated response propensities grouped into 5 and 10 classes.  Propensity model estimated based on the four variables available for respondents and nonrespondents using a model with main effects and all two-way interactions. A dot marks the average propensity in each class. Figure 16.1 shows boxplots of the estimated propensities from the model for the 5 and 10 class breakdowns.  The ranges are fairly wide in each of the 5 classes, but noticeably less within each of the 10 classes.  As a further diagnostic, we can check whether balance was achieved for the covariates in the 10-class breakdown.  The following R code creates an indicator for whether a person is in the Army National Guard and checks balance.

\noindent v1 $<$- rep(0,nrow(sofr.d1.elig))

\noindent v1 $<$- sofr.d1.elig\$xsrrcr == 1      \# Army National Guard

\noindent 

\noindent chk $<$- glm(v1 \~{} as.factor(p.class.10) + as.factor(resp) + as.factor(p.class.10)*as.factor(resp), 

\noindent             family=binomial(link = "logit"),

\noindent         data = sofr.d1.elig)

\noindent anova(chk, test="Chisq")

\noindent 

\noindent The output of the anova statement is

\begin{tabular}{|p{1.4in}|p{0.3in}|p{0.6in}|p{0.5in}|p{0.6in}|p{0.6in}|p{0.3in}|} \hline 
 & Df & Deviance & Resid. Df & Resid. Dev & P($>$\textbar Chi\textbar ) &  \\ \hline 
as.factor(p.class.10) & 9 & 12764.8 & 66138 & 59225 & $<$ 2.2e-16 & *** \\ \hline 
as.factor(resp) & 1 & 8.9 & 66137 & 59217 & 0.00288 & ** \\ \hline 
as.factor(p.class.10):\newline    as.factor(resp) & 9 & 24.5 & 66128 & 59192 & 0.00364 & ** \\ \hline 
\end{tabular}



\noindent Similar checks (not shown here) reveal that the interaction term is significant when predicting whether a person is in the Army Reserve, is in pay group E1-E3, or is non-Hispanic White.  As a result, the model with two-way interactions does not achieve statistical balance.  In part, this is probably due to the extremely large sample in which small effects test out as statistically significant, and, in part, to misspecification of the model itself.  In particular, there may be higher order interactions.  Using a regression tree may be one way of finding these.

\noindent \textbf{Regression Tree}

 Using the same four variables as above---service, pay group, gender, and race-ethnicity---we fit a CART model with this code:

\noindent t1  $<$-  rpart(resp \~{} xcpay1r + xreth4r + xsexr + xsrrcr,

\noindent                    method = "class",

\noindent                    control = rpart.control(minbucket = 250, cp=0),

\noindent                    data = sofr.d1.elig)

\noindent 

\noindent The tree with 13 terminal nodes is shown in Figure 16.2.  As is apparent from the figure, the structure has some complicated combinations.  Table 16.8 gives the descriptions of the nodes.  The CART classes are numbered differently by the print method than in the object t1\$where.  The highest ranking officers have the highest response rates; this is reflected in class 25 \eqref{GrindEQ__7_} containing pay groups O4-O6 which has a response rate of 0.631 (unweighted) and 0.672 (weighted).  Enlisted personnel did not respond well---CART put all E1-E6's in class 2, which has unweighted and weighted rates of  0.272 and 0.321.  Among higher paid personnel, Marines are some of the poorest responders.  For example, class 21 \eqref{GrindEQ__104_}, containing E7-E9, non-Hispanic Whites in the Marine Corps Reserve had an unweighted rate of 0.385 (0.410 weighted).  The numbers of persons in the CART classes range from 296 to 41,380, which are obviously far from the more nearly equal-sized classes in the propensity analysis.  Note that 41,380 of the 66,148 eligibles (62.6\%) are in the same class and are assigned the same response rate.  

Since the classes formed by the regression tree seem to capture the complexity of the response process better than the logistic model, the classes in Table 16.8 will be used for nonresponse adjustment.  We used weighted response rates to make the weight adjustment in each class.  The weighted values are shown in the last column of Table 16.8.  As mentioned in Chapter 13, not all practitioners will agree on whether the weighted or unweighted rates should be used.  Using the weighted rates is, in a sense, a compromise solution.  Conditional on the classes formed, the weighted rates are model-unbiased under a model in which every person in a class has a common probability of responding.  They are also approximately unbiased estimates of the population response rates in repeated sampling given the particular set of classes used.

\noindent \textbf{\eject }

\noindent \textbf{Table 16.8  }Nonresponse adjustment classes created using a regression tree. 

\begin{tabular}{|p{0.6in}|p{0.6in}|p{2.4in}|p{0.6in}|p{0.7in}|p{0.6in}|} \hline 
CART class (t1\$where) & CART class (print) & Description & No. of persons & Unweighted response rate & Weighted response rate \\ \hline 
2 & 2 & E1-E3, E4, E5-E6 & 41,380  & 0.272 & 0.321 \\ \hline 
7 & 48 & E7-E9, W1-W5, O1-O3, Minority, Marine Corps Reserve & 669  & 0.426 & 0.406 \\ \hline 
9 & 98 & E7-E9, W1-W5, O1-O3, Minority, Army National Guard & 1,125  & 0.453 & 0.481 \\ \hline 
12 & 396 & E7-E9, W1-W5, O1-O3, Minority, Army Reserve, Female & 473  & 0.469 & 0.471 \\ \hline 
14 & 794 & E7-E9, Minority, Army Reserve, Male & 562  & 0.496 & 0.485 \\ \hline 
15 & 795 & W1-W5, O1-O3, Minority, Army Reserve, Male & 602  & 0.508 & 0.517 \\ \hline 
16 & 199 & E7-E9, W1-W5, O1-O3, Minority, Naval Reserve & 296  & 0.554 & 0.525 \\ \hline 
17 & 25 & E7-E9, W1-W5, O1-O3, Minority, Air National Guard, Air Force Reserve & 1,239  & 0.530 & 0.544 \\ \hline 
21 & 104 & E7-E9, non-Hispanic White, Marine Corps Reserve & 494  & 0.385 & 0.410 \\ \hline 
22 & 105 & W1-W5, O1-O3, non-Hispanic White, Marine Corps Reserve & 561  & 0.510 & 0.509 \\ \hline 
23 & 53 & E7-E9, W1-W5, O1-O3, non-Hispanic White, Air National Guard, Air Force Reserve & 3,321  & 0.578 & 0.612 \\ \hline 
24 & 27 & E7-E9, W1-W5, O1-O3, non-Hispanic White, Army National Guard, Army Reserve, Naval Reserve & 5,941  & 0.586 & 0.586 \\ \hline 
25 & 7 & O4-O6 & 9,485  & 0.631 & 0.672 \\ \hline 
\end{tabular}

\textbf{}

\noindent \eject \includegraphics*[width=9.06in, height=4.56in, keepaspectratio=false, trim=1.19in 0.73in 0.99in 0.59in]{image2.eps}

\noindent \textbf{Figure 16.2}  Regression tree to predict response based on the four variables available for respondents and nonrespondents.

\noindent 

\noindent \textbf{16.6  Calibration to Population Counts}

\noindent 

 The final weighting step in this project will be calibration to some of the available population counts.  The statistical function that calibration serves here is mainly to reduce standard errors.  Since military administrative records should be accurate, there should be no systematic over- or under-coverage to be corrected.  In addition, calibration has some cosmetic appeal here.  Having estimated counts exactly equal to ones from administrative personnel records will give the survey results face validity---a feature that may be important to many data users.  There are two major operational questions that must be addressed:

\begin{enumerate}
\item  Which variables and/or combinations of variables should be used for calibration?

\item  How should missing values for the calibrating variables be handled in the sample file and the file of population counts?
\end{enumerate}

\noindent The code for completing the analyses sketched below is in the file 16.3 Solution calibration adj.R on the website.

 Other questions that we will not address here, but would be important in a real survey, are: 

\begin{enumerate}
\item  For what time period should population counts be made when there is a delay between sample selection and data collection?

\item  Which persons should be counted to get the controls?
\end{enumerate}

\noindent Administrative record databases are typically updated periodically---once a month, once a quarter, etc.  There may also be a lag between the time period of the database and the time at which it is available for tabulation.  This means that population counts may not be for the time period when data are collected.  In addition, data collection may extend across two or more updates of the administrative data.  For example, there might be a 2-month lag between sample selection and data collection, the survey period may last 10 weeks, and the administrative records may be updated once a month.  When such a lag occurs, the persons who are surveyed will be the ``survivors'', i.e., the ones who were in the frame when the sample was selected and are still eligible when data are collected.  No new entrants to the population would be included in the sample.  If the population counts are made close to the time of data collection and include all persons who are eligible based on the survey rules, then the counts would include the new entrants who had no chance of being sampled.  If we calibrate to these counts, we are saying that the attitudes of the new entrants can be predicted by those of the sample persons who have been in the population longer.  Another option would be to tabulate the control counts using only persons who have been in the military for at least two months, if that is the amount of lag between sampling and data collection.  In some surveys, like those of the U.S. household population, such selective tabulations may not be feasible.

In this project, we will use the population counts as given in the RCCPDS57.sas7bdat file.  As noted in Chapter 12, this file came from matching the sampling frame to the most current personnel file available as of the start of the data collection period.  That is, the counts are those of the survivors.  Thus, these counts should cover only eligible cases.

\noindent 

\noindent \textbf{Identifying Variables to Use}

 The file of population counts contains combinations of service, gender, pay group, race-ethnicity, education, marital status, and length of activation.  All of these are categorical and can be used singly or in any number of combinations.  We could, for example, use only the marginal counts of service, pay group, and gender.  Or, we could use service $\times$ pay group and service $\times$ gender; or, service $\times$ pay group $\times$ gender.  Some modeling is a useful approach to guide the decision.  The goal will be to determine one set of weights that is reasonably efficient for the important variables measured in the survey.  We have six analysis variables listed in Table 16.1 (RA006a, RA006B, RA008, RA115, RA118, and RA112RA) to aid in making the decision.  

 To do the modeling we created several binary variables. Satisfaction with compensation (RA006a) and type of work (RA006b) were coded as Satisfied/(Very Satisfied) = 1 and 0 otherwise.  Likelihood of re-enlisting (RA008) was coded as (Likely/Very likely) = 1 and 0 otherwise.  Preparation for job (RA115) was coded as (Well prepared)/(Very well prepared) = 1 and 0 otherwise.  Level of stress was coded as (More than usual)/(Much more than usual) = 1 and 0 otherwise.  Finally, days in compensated status (RA112RA) was used as a continuous variable.

 Rather than fitting binary regressions where the form of the predictors is specified in advance, we again used regression trees to allow the algorithm to identify the more important variables and combinations of levels for prediction.  Since the intention to re-enlist is a key variable in this survey, we present those results here.  Figure 16.3 shows the regression tree for predicting whether a person is Likely/Very likely to re-enlist.  The code for computing the tree and drawing the figure is:

\noindent t1 $<$- rpart(ra008R \~{} xsrrcr + xsexr + xcpay1r + xreth4r + 

\noindent                      sred + srmarst + xact2r,

\noindent                    method = "class",

\noindent                    control = rpart.control(minbucket = 250, cp=0),

\noindent                    data = datafile)

\noindent plot(t1, uniform=TRUE, compress=TRUE, margin = 0.1, branch=0)

\noindent text(t1, use.n=TRUE, all=TRUE,

\noindent      digits=15,

\noindent      cex=1.2,

\noindent      pretty=1.2,

\noindent      fancy=TRUE,

\noindent      fwidth=0.7,

\noindent      xpd = TRUE, 

\noindent      font = 3)

\noindent 

\noindent The parameter branch=0 gives a tree with V-shaped branches, which, in this case, makes the branch labels easier to read.  Pay group, branch of service, whether a person had been activated for 30 days or more, and marital status are included in the tree; gender, race-ethnicity, and education are not.  

\noindent 

\noindent \includegraphics*[width=9.11in, height=4.60in, keepaspectratio=false, trim=1.05in 0.68in 0.88in 0.48in]{image3.eps}

\noindent 

\noindent \textbf{Figure 16.3  }Regression tree for predicting likelihood of re-enlisting

\noindent 

\noindent Table 16.9  Variables included in regression trees for predicting six analysis variables 

\begin{tabular}{|p{0.7in}|p{0.8in}|p{0.5in}|p{0.5in}|p{0.5in}|p{0.5in}|p{0.6in}|p{0.5in}|p{0.6in}|} \hline 
~ & ~ & \multicolumn{7}{|p{3.7in}|}{Predictors} \\ \hline 
Name & Analysis variable & Service  & Gender  & Pay group & Race-ethnicity & Education & Marital status & Activation \\ \hline 
RA006A & Compensation & ü &  & ü & ü & ü &  & ü \\ \hline 
RA006B & Type of work & ü &  & ü &  & ü & ü & ü \\ \hline 
RA008R & Re-enlist & ü &  & ü &  &  & ü & ü \\ \hline 
RA115R & Preparation & ~ & ü & ü & ü &  &  & ü \\ \hline 
RA118 & Stress & ü &  & ü & ü &  &  & ü \\ \hline 
RA112RA & Paid status & ü & ~ & ü & ü & ü & ü & ü \\ \hline 
\end{tabular}



 Table 16.9 summarizes which variables were included in the trees for predicting the six analysis variables.  Gender was selected only to predict whether people felt prepared to do their jobs.  Examination of the individual trees shows that service $\times$ pay and service $\times$ activation interactions are always present.  Often there are more complicated interactions, as in Figure 16.3 where there is a combination of service, pay group, activation, and marital status.  However, including 3-way and 4-way interactions would lead to samples that are very thin in some combinations of levels even though there are over 25,000 respondents.  Based on these results, we decided to use a calibration model with 

\begin{enumerate}
\item  main effects for service, gender, pay group, race-ethnicity, education, marital status, and actvation;

\item  interactions for service $\times$ pay and service $\times$ activation.
\end{enumerate}

\noindent Although gender only appears once in Table 16.9, we include it for the cosmetic benefit of matching the administrative record count for males and females.

\noindent 

\noindent \textbf{Imputing for Missing Values}

 Tables 16.6a and 16.6b showed that the file from which population counts were made had missing values for some persons for service, race-ethnicity, gender, education, marital status, and activation.  The percentage of persons with missing values ranged from 0.04\% for service to 3.3\% for education.  To impute for the missing values, we need only impute a covariate value whenever it was missing in the RCCPDS57.sas7bdat  file.  For example, here is one record in the file that had a missing value for service:

\noindent 

\begin{tabular}{|p{0.5in}|p{0.5in}|p{0.5in}|p{0.5in}|p{0.5in}|p{0.5in}|p{0.5in}|p{0.5in}|} \hline 
service & gender & pg\_group & raceth & educcat & marit & activatd & count \\ \hline 
. & 2 & 2 & 2 & 4 & 5 & 3 & 159 \\ \hline 
\end{tabular}



\noindent To impute the missing service, a random draw is made from allowable the codes in proportion to the population code-counts for the non-missing records.  The R code for doing the population count imputations is in the function, impute, in the file 16.3 Solution calibration adj.R.  

 The sample file also has some records with missing data on the covariates that will be used for calibration.  Table 16.6b shows that 2.1\% of the 25,559 respondents are missing education, 0.1\% are missing marital status, and 0.5\% are missing the activation field.  Any missing value for a sample respondent was imputed with a random draw from the allowable codes for a variable.  The draws were made in proportion to the distribution among the codes for persons with non-missing data.  The R code for doing the sample imputations is in the function, impute.sam, which is also in 16.3 Solution calibration adj.R.  

These imputation methods are straightforward and could be criticized as not accounting for any multivariate relationships among different variables.  Given the small amount of missing data for all variables, we elected to keep the methods simple.

\noindent 

\noindent \textbf{GREG Estimation}

Using the files of sample respondents and population counts with all missing values imputed, we calibrated to the population totals using a GREG estimator.  When using the calibrate function in R survey, some care is needed to be sure that the vector of population totals is in exactly the same order as is being used internally by calibrate.  The function model.matrix will create the model-matrix of covariates that calibrate uses for a particular formula.  In this application, we check the order with: 

\noindent 

\noindent         \# check how design matrix is formed in calibrate

\noindent mm $<$- model.matrix(\~{} as.factor(xsrrcr) * as.factor(xcpay1r) 

\noindent                     + as.factor(xsrrcr) * as.factor(xact2r)

\noindent                     + as.factor(sred)

\noindent                     + as.factor(xsexr) 

\noindent                     + as.factor(xreth4r)

\noindent                     + as.factor(srmarst),

\noindent                     data = sofr.cal)

\noindent dimnames(mm)[[2]]

\noindent 

\noindent The last statement lists the column names of the model-matrix.  The interactions are in ``row-major'' order.  For example, the first five values of the service $\times $ paygrade interaction are

\noindent "as.factor(xsrrcr)2:as.factor(xcpay1r)2"

\noindent "as.factor(xsrrcr)3:as.factor(xcpay1r)2"

\noindent "as.factor(xsrrcr)4:as.factor(xcpay1r)2"

\noindent "as.factor(xsrrcr)5:as.factor(xcpay1r)2"

\noindent "as.factor(xsrrcr)6:as.factor(xcpay1r)2"

\noindent 

\noindent That is, service is incremented before paygrade.  The code for putting the population controls in the correct order and for computing the GREG weights follows.  Prior to this code counts for service $\times $ paygrade and service $\times $ activation were made and stored in the objects svc.pay1 and svc.act1.

\noindent 

\noindent         \# reorder the pop totals for the interaction terms to match 

\noindent         \# way that calibrate creates model matrix

\noindent svc.pay1 $<$- svc.pay[order(svc.pay[,2]),]

\noindent svc.act1 $<$- svc.act[order(svc.act[,2]),]

\noindent del1 $<$- svc.pay1[,1]==1 \textbar  svc.pay1[,2]==1

\noindent del2 $<$- svc.act1[,1]==1 \textbar  svc.act1[,2]==1

\noindent 

\noindent pop.tots $<$- c(N,

\noindent               svc[-1,2],

\noindent               pay[-1,2],

\noindent               activated[-1,2],

\noindent               educ[-1,2],

\noindent               gender[-1,2],

\noindent               raceth[-1,2],

\noindent               marital[-1,2],

\noindent               svc.pay1[!del1,3],

\noindent               svc.act1[!del2,3])

\noindent 

\noindent sam.lin.ub  $<$-  calibrate(design = sofr.cal.dsgn,

\noindent                     formula = \~{}  as.factor(xsrrcr) * as.factor(xcpay1r) 

\noindent                     + as.factor(xsrrcr) * as.factor(xact2r)

\noindent                     + as.factor(sred)

\noindent                     + as.factor(xsexr) 

\noindent                     + as.factor(xreth4r) 

\noindent                     + as.factor(srmarst),

\noindent                     population = pop.tots,

\noindent                     bounds = c(-Inf,Inf),

\noindent                     calfun = c("linear")

\noindent )

\noindent 

Table 16.10 gives some summary statistics on the weights after each step in the process.  The mean weight is about the same before and after the GREG step, while the range is larger for the GREG weights than for the nonresponse-adjusted weights.  The sum of the weights is smallest after the GREG step (801,809) accounting for the fact that some persons became ineligible between sampling and data collection and that the control totals are for the survivors only.

\noindent 

\noindent Table 16.10  Summary of weights and counts of persons after each step.

\begin{tabular}{|p{1.5in}|p{0.5in}|p{0.5in}|p{0.5in}|p{0.5in}|p{0.5in}|p{0.5in}|p{0.6in}|p{0.6in}|} \hline 
Weighting step & Min. & 1st Qu. & Median & Mean & 3rd Qu. & Max. & Sum & Persons \\ \hline 
Base & 1 & 2.201 & 5.049 & 12.14 & 14.27 & 178.3 & 870,373  & 71,701  \\ \hline 
Adjusted for unknown eligibility & 1.023 & 2.251 & 5.05 & 12.3 & 14.59 & 182.3 & 813,342  & 66,148  \\ \hline 
Adjusted for nonresponse & 1.521 & 4.746 & 14.63 & 31.82 & 34.31 & 514.7 & 813,342  & 25,559  \\ \hline 
GREG & 1.199 & 4.672 & 13.43 & 31.37 & 30.91 & 613.4 & 801,809  & 25,559  \\ \hline 
\end{tabular}



In this solution weight trimming was not used, although some practitioners might consider it.  Although the range of final weights is fairly large---1.199 to 613.4---the base weights began with a wide range owing to the highly differential sampling rates that were used.  The base weights were adjusted to reflect substantially different response rates among some types of personnel.  Consequently, the final weights have a wide range.  This is necessary to correct nonresponse bias for some subgroups.  However, the 99${}^{th}$ quantile of the final weights is about 385 while the maximum final weight is 613.4.  Trimming of the largest 1\% of weights might reduce SE's for full population estimates without introducing too much bias, but estimates for the subgroups with very low response rates might then be biased.  As usual, we are faced with conflicting goals with no unique way of achieving them.

\noindent \textbf{}

\noindent \textbf{16.7 Writing Output Files}

 The resulting file with the GREG weights can be written to comma delimited (csv) text files for use in other statistical software.  The code below appends the GREG weight to the file, selects fields for output, and writes the text files.  The write.foreign function in the foreign package will also write code to be used in importing the csv files into a few other packages.  We illustrate the process below for SAS and Stata.  

\noindent         \# append GREG weights to data file of 25,559 respondents

\noindent sofr.cal\$d3 $<$- weights(sam.lin.ub)

\noindent 

\noindent         \# specify fields for the text, SAS, and Stata files

\noindent fields $<$- c("rec.id", "nr.class", "respstat", "stratum",

\noindent             "nsamp", "nstrat", "v.strat",

\noindent             "srmarst", "sred", "xsrrcr", "xact2r", 

\noindent             "xreth4r", "xsexr", "xcpay1r",   

\noindent             "ra006a", "ra006b", "ra008", "ra115", "ra118", "ra112ra", 

\noindent             "pred.logit", "p.class.10", "unwt.rr", "wt.rr",

\noindent             "d0", "d1", "a1", 

\noindent             "d2", "a2",         

\noindent             "d3")

\noindent 

\noindent write.foreign(df = sofr.cal[, fields], 

\noindent               datafile = paste(file\_loc2, "sofr.cal.sas.csv", sep=""), 

\noindent               codefile = paste(file\_loc2, "sofr.sas", sep=""), 

\noindent               package = "SAS")

\noindent 

\noindent write.foreign(df = sofr.cal[, fields], 

\noindent               datafile = paste(file\_loc2, "sofr.cal.stata.csv", sep=""), 

\noindent               codefile = paste(file\_loc2, "sofr.ado", sep=""), 

\noindent               package = "Stata")

\noindent 

\noindent The reader can consult the programs, 16.1 Solution bwt-unknown adj.R, 16.2 Solution NR adj.R, and 16.3 Solution calibration adj.R, to see how the different variables were created.  

Although the data can be imported into statistical packages other than R, a worry is that the other packages do not have built-in procedures that recognize that the weights were computed via the GREG procedure.  This, typically, means that linearization variance estimates will be computed using the ultimate cluster method discussed in Chapter 15 that does not use the correct set of residuals.  As a result, linearization SE's computed from the other packages will not generally be correct.  This problem can be avoided if replication is used.  In that case, the set of replication weights can appropriately reflect the different steps in weighting, particularly the type of calibration that was used.  The replicate weights are included with the data set, and a package like SAS or Stata needs only to be told which method of replication was used---jackknife, BRR, or the bootstrap---in order to produce legitimate SE's.

\noindent 

\noindent \textbf{16.8  Example Tabulations}

Finally, in this section we present a few simple tabulations using the file with the final weights.  R Code is in the file, 16.4 Example tabulations.R.  The proportions of persons responding in the categories of the re-enlistment question (ra008) can be estimated with:



\noindent             \# proportions for re-enlistment item

\noindent reenlist $<$- svymean(\~{} as.factor(ra008), design = sam.lin.ub, 

\noindent                     na.rm = TRUE)

\noindent 

\noindent             \# format with row labels

\noindent print(ftable(reenlist, 

\noindent         rownames = list(c("Very unlikely", 

\noindent                           "Unlikely",

\noindent                           "Neither likely nor unlikely",

\noindent                           "Likely",

\noindent                           "Very likely")

\noindent                     )

\noindent ), digits = 3)

\noindent 

\noindent The function ftable allows labels to be used for the printed output.  The results, even with the use of ftable which improves the appearance, is not beautiful:

\noindent Very unlikely               mean  0.06608

\noindent                             SE    0.00357

\noindent Unlikely                    mean  0.10924

\noindent                             SE    0.00428

\noindent Neither likely nor unlikely mean  0.09280

\noindent                             SE    0.00386

\noindent Likely                      mean  0.31757

\noindent                             SE    0.00611

\noindent Very likely                 mean  0.41431

\noindent                             SE    0.00619

\noindent 

\noindent If a table is needed for a report, one option is to import the output into a spreadsheet where more attractive formatted can be applied.  Suppose that the result of print(ftable(reenlist, \dots )) is saved to an object called out.  Code that will convert out to a data frame, put the proportion and SE side by side, and write the result to a file called table.csv is:

\noindent 

\noindent out $<$- data.frame(out)

\noindent out $<$- cbind(out[1:5,], out[6:10,])

\noindent out $<$- out[, c(1,3,6)]

\noindent dimnames(out)[[2]] $<$- c("Response", "Proportion", "SE")

\noindent write.csv(out, file = "c:\textbackslash \textbackslash table.csv")

\noindent 

\noindent 


\end{document}

